{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the third project of Udcaity Self-Driving Car Engineer Nanodegree program. \n",
    "\n",
    "Here is the 4 major files of the project:\n",
    "\n",
    "* model.py \n",
    "\n",
    "    containing the script to create and train the model\n",
    "    \n",
    "    \n",
    "* drive.py \n",
    "\n",
    "    for driving the car in autonomous mode\n",
    "    \n",
    "    \n",
    "* outputs/steering_model/steering_angle.h5model.h5 \n",
    "\n",
    "    containing a trained convolution neural network\n",
    "    \n",
    "    \n",
    "* writeup_report.md or writeup_report.ipynb \n",
    "    \n",
    "    this file, which summarizing the results\n",
    "    \n",
    "The car can be driven autonomously around the track by executing `$ python drive.py ./outputs/steering_model/steering_angle.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "import cv2\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage as sndi\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_steering_angle_distribution(y_train, groups = 500):\n",
    "    plt.title(\"Steering angle distribution in data\")\n",
    "    plt.hist(y_train, groups)\n",
    "    plt.show()\n",
    "    \n",
    "    positive_angle = [i for i in y_steering if i > 0]\n",
    "    nagative_angle = [i for i in y_steering if i < 0]\n",
    "    zero_angle = [i for i in y_steering if i == 0]\n",
    "\n",
    "    print('number of positive angle:', len(positive_angle))\n",
    "    print('number of negative angle:', len(nagative_angle))\n",
    "    print('number of zero angle:', len(zero_angle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stated my network with data provided by Udacity. However, I found that I may need extra data because the model is not working well. So I drove the car, and collected 10 more groups of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drive_log_files = [\n",
    "    'driving_log.csv', # data provided by Udacity\n",
    "    'additional_data_1/driving_log.csv', # 2 full laps\n",
    "    'additional_data_2/driving_log.csv', # 5 runs, from the begining of the first curve to the bridge\n",
    "    'additional_data_3/driving_log.csv', # 3 full laps\n",
    "    'additional_data_4/driving_log.csv', # 3 runs, from the begining of the first curve to the starting point of trainig mode\n",
    "    'additional_data_5/driving_log.csv', # 5 runs show that how to get back to the middle of the road while the car is going to leave the road\n",
    "    'additional_data_6/driving_log.csv', # 5 runs show that how to get back to the middle of the road while the car is running on the lane line\n",
    "    'additional_data_7/driving_log.csv', # 6 run, from the begining of the road fork to the point where the roads merge\n",
    "    'additional_data_8/driving_log.csv', # 5 runs, from the end of the first curve to the end of the bridge\n",
    "    'additional_data_9/driving_log.csv', # 1 run, from the end of the bridge to the starting point of training mode\n",
    "    'additional_data_10/driving_log.csv' # 4 full laps\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_center = []\n",
    "X_left = []\n",
    "X_right = []\n",
    "y_steering = []\n",
    "\n",
    "for drive_log_file in drive_log_files:\n",
    "    with open(drive_log_file, 'rt') as csvfile:\n",
    "        reader = csv.reader(csvfile, skipinitialspace=True)\n",
    "\n",
    "        next(reader) # skip the first row\n",
    "\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            i = i+1\n",
    "            X_center.append(row[0])\n",
    "            X_left.append(row[1])\n",
    "            X_right.append(row[2])\n",
    "            y_steering.append(float(row[3]))\n",
    "\n",
    "X_center = np.array(X_center)\n",
    "X_left = np.array(X_left)\n",
    "X_right = np.array(X_right)\n",
    "y_steering = np.array(y_steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_steering_angle_distribution(y_steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I notice that the number of samples with around zero steering angle are much higher then any other. It may because the car is driving on a strength line most of the time. The car may not have to adjust the steering angle unless there is a curve.\n",
    "\n",
    "On the other hand, I find that the number of sample with negative steering angle is much higher that the positive one. It is because the track we used has many left turns but only one right turn. So if the car needs to turn, then the chance that the car turns left is higher then a right turn.\n",
    "\n",
    "If we train on these sample directly, we may obtains a model that perfer driving strength or turning left, and resisting to turning right. The model may be overfitting.\n",
    "\n",
    "As a result, we may need to adjust the distribution before training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Camera images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Use side camera images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "index = 25 \n",
    "\n",
    "a=fig.add_subplot(1,3,1)\n",
    "img = mpimg.imread(X_left[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Left')\n",
    "\n",
    "a=fig.add_subplot(1,3,2)\n",
    "img = mpimg.imread(X_center[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Center')\n",
    "\n",
    "a=fig.add_subplot(1,3,3)\n",
    "img = mpimg.imread(X_right[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample contains three images from different cameras. All carmera are facing forward, however, they are in differnce positions. \n",
    "\n",
    "If the center camera captures an image similar to the image from left camera, then the car may be on the left of the road and it should turns a little bit right, such that the center image should looks like what we seen in the sample. We may add Â±0.15 steering angle to side camera images, to simulate the situration that the car is driving on the side way, and it should turn a little bit. \n",
    "\n",
    "If we use both side camera images, we will have triple number of sample images for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fliped_image(image):\n",
    "    return cv2.flip(image, flipCode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "index = 25\n",
    "\n",
    "a = fig.add_subplot(1,2,1)\n",
    "img = mpimg.imread(X_left[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Original')\n",
    "\n",
    "a = fig.add_subplot(1,2,2)\n",
    "img = mpimg.imread(X_center[index])\n",
    "imgplot = plt.imshow(fliped_image(img))\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Fliped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image can be fliped, and the fliped sample should have a steering angle with oppsite signs. Let say we fliped an image with steering angle 0.5, then the fliped image should have steering angle -0.5. \n",
    "\n",
    "As a result, we have double our training images. And we should have equal numbers of sample with positive and negative angle. \n",
    "\n",
    "By the way, fliping an image with 0 steering angle results in a new sample with zero steering angle. In order to reduce the difference in samples with and without zero steering angle, no image with zero steering angle will be fliped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiply images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use side camera images\n",
    "y_steering_left = y_steering + 0.15\n",
    "y_steering_right = y_steering - 0.15\n",
    "y_steering = np.append(y_steering, y_steering_left, axis=0)\n",
    "y_steering = np.append(y_steering, y_steering_right, axis=0)\n",
    "\n",
    "# flip all images with non-zero steering angles\n",
    "y_steering = np.append(y_steering, -(y_steering[y_steering != 0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_steering_angle_distribution(y_steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned before, I will multiply number of samples by flipping images and using side camera images.\n",
    "\n",
    "All the image with non-zero steering angle will be fliped and each fliped image will have steering angle in oppsite sign of the orignal one.\n",
    "\n",
    "The steering angle of left camera image will be *original steering angle + 0.15*.\n",
    "\n",
    "The steering angle of right camera image will have steering angle equals to *original steering angle - 0.15*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tuning given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cropped_image(image):\n",
    "    shape = image.shape\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    return image[65:height-35, 0:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_in_yuv(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_resized_image(image):\n",
    "    return cv2.resize(image.astype(np.uint8), (200, 66), cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_blured_image(image):\n",
    "    return cv2.bilateralFilter(image,9,75,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_image(image):\n",
    "    image = get_cropped_image(image)\n",
    "    image = get_resized_image(image)\n",
    "    image = get_image_in_yuv(image)\n",
    "    image = get_blured_image(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "index = 25\n",
    "\n",
    "a = fig.add_subplot(1,2,1)\n",
    "img = mpimg.imread(X_center[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Original')\n",
    "\n",
    "a = fig.add_subplot(1,2,2)\n",
    "img = get_preprocessed_image(mpimg.imread(X_center[index]))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images will be preprocess by 4 steps. They are **Cropping**, **Resizing**, **Converting colorspace** and **Bluring**.\n",
    "\n",
    "The detail of each steps are descriped as follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Crop image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "index = 25\n",
    "\n",
    "a = fig.add_subplot(1,2,1)\n",
    "img = mpimg.imread(X_center[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Original')\n",
    "\n",
    "a = fig.add_subplot(1,2,2)\n",
    "img = get_cropped_image(mpimg.imread(X_center[index]))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Croped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower part of the images contain the car body and no lane lines. The lower parts contain no useful information for determine steering angle, so it should be safe to remove them. I remove the upper 65px from the sample.\n",
    "\n",
    "The upper part of the images include sky and trees but not the road or lane line. The steering angle should not count on the sky or trees, so it should be safe to remove the upper part of the images. I remove the lower 35px from the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Convert colorspace to HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "index = 25\n",
    "\n",
    "a = fig.add_subplot(1,2,1)\n",
    "img = mpimg.imread(X_center[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('RGB')\n",
    "\n",
    "a = fig.add_subplot(1,2,2)\n",
    "img = get_image_in_yuv(mpimg.imread(X_center[index]))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('HSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nvidia paper suggested that we can use HSV colorspace.\n",
    "\n",
    "Seems that the boarder of the road is more obvious in HSV colorspace, so I decided to use HSV colorspace instead of RGB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "index = 25\n",
    "\n",
    "a = fig.add_subplot(1,2,1)\n",
    "img = mpimg.imread(X_center[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Original')\n",
    "\n",
    "a = fig.add_subplot(1,2,2)\n",
    "img = get_resized_image(mpimg.imread(X_center[index]))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Resized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nvidia paper recommands that we can use image with size (200, 66).\n",
    "\n",
    "Because I may want to use Nvidia model, so I decided to follow their suggestion and  resize the image to (200, 66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Blured image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "index = 25\n",
    "\n",
    "a = fig.add_subplot(1,2,1)\n",
    "img = mpimg.imread(X_center[index])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Original')\n",
    "\n",
    "a = fig.add_subplot(1,2,2)\n",
    "img = get_blured_image(mpimg.imread(X_center[index]))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "a.set_title('Resized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern of the road is meaningless, so I blured the image.\n",
    "\n",
    "Although the images are blured, the border is still obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model I used is based on the steering model provided by comma.ai.\n",
    "\n",
    "Most the the layer are kept, and only the normalization layer is changes, I updated the Lambda layer parameter from `Lambda(lambda x: x/127.5 - 1., input_shape=(ch, row, col), output_shape=(ch, row, col)` to `Lambda(lambda x: x/255 - 0.5, input_shape=shape)`, such that the channel is kept as the last parameter, and the formula that I used to get the normalized value is changed. The Lambda layer I used is copied from the Q&A session video on YouTube.\n",
    "\n",
    "The summary of my network is mentioned below:\n",
    "```\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "lambda_1 (Lambda)                (None, 66, 200, 3)    0           lambda_input_1[0][0]             \n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_1 (Convolution2D)  (None, 17, 50, 16)    3088        lambda_1[0][0]                   \n",
    "____________________________________________________________________________________________________\n",
    "elu_1 (ELU)                      (None, 17, 50, 16)    0           convolution2d_1[0][0]            \n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_2 (Convolution2D)  (None, 9, 25, 32)     12832       elu_1[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "elu_2 (ELU)                      (None, 9, 25, 32)     0           convolution2d_2[0][0]            \n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_3 (Convolution2D)  (None, 5, 13, 64)     51264       elu_2[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 4160)          0           convolution2d_3[0][0]            \n",
    "____________________________________________________________________________________________________\n",
    "dropout_1 (Dropout)              (None, 4160)          0           flatten_1[0][0]                  \n",
    "____________________________________________________________________________________________________\n",
    "elu_3 (ELU)                      (None, 4160)          0           dropout_1[0][0]                  \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 512)           2130432     elu_3[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "dropout_2 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
    "____________________________________________________________________________________________________\n",
    "elu_4 (ELU)                      (None, 512)           0           dropout_2[0][0]                  \n",
    "____________________________________________________________________________________________________\n",
    "dense_2 (Dense)                  (None, 1)             513         elu_4[0][0]                      \n",
    "====================================================================================================\n",
    "Total params: 2,198,129\n",
    "Trainable params: 2,198,129\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first started with Udacity data, and the car leaves the road at the first lap. I think the model is over fitting.\n",
    "\n",
    "In order to fix the overfitting, we can tune the network or add additional data. I do not want to tuning the parameters, so I decidied to solve the problem by feeding more data to the network.\n",
    "\n",
    "Once I find that the car cannot finish the race, then I will start recording new training data. The new training data may be a full laps or only part of the track. If the new training data contains only part of the track, then the training is forced on fixing a specified problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('Screen_Shot_1.png')\n",
    "plt.imshow(image)\n",
    "plt.title('The car leaving the road')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After my trial ends with above situration, I started collecting *additional_data_5*, which shows how to get back to the middle of the road while the car is going to leave the road. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('Screen_Shot_2.png')\n",
    "plt.imshow(image)\n",
    "plt.title('The car driving on the lane line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although my car didn't cross the border, I believed it was too dangous to drive on the lane line, so I started collecting *additional_data_6*, which shows how to get back to the middle of the road from the lane line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final output of my network on the sample track (Click to play on YouTube)\n",
    "\n",
    "[![A car driving on the sample track](https://img.youtube.com/vi/xj-v50t6qS0/0.jpg)](https://www.youtube.com/watch?v=xj-v50t6qS0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[comma.ai](https://github.com/commaai/research) -- The architecture of steering angle model, the code for saving the model. All of these are released under [BSD License](https://github.com/commaai/research/blob/master/LICENSE)\n",
    "\n",
    "[Udacity](https://www.udacity.com) -- Sample data and the base of the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
